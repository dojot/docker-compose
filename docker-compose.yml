version: '3.8'

# https://docs.docker.com/config/containers/logging/json-file/
# https://docs.docker.com/config/containers/logging/log_tags/
x-logging: &loki-logging
  logging:
    driver: 'json-file'
    options:
      max-size: '50m'
      max-file: '3'
      tag: "{{.ImageName}}|{{.Name}}|{{.ImageFullID}}|{{.FullID}}"

x-networking: &dojot-networking
  networks:
    - default

services:

  create_secrets:
    # To recreate the secrets, reset the files: MINIO_ACCESS_KEY, MINIO_SECRET_KEY which are in the docker-compose/secrets folder.
    image: dojot/ubuntu_openssl:latest
    command:
        - "./secrets/create_secrets.sh"
    restart: on-failure
    volumes:
      - ./secrets:/secrets

  history:
    image: dojot/history:${DOJOT_BACKEND_VERSION}
    restart: always
    depends_on:
      - mongodb
    environment:
      FALCON_SETTINGS_MODULE: 'history.settings.docker'
      DOJOT_MANAGEMENT_USER: 'history'
      LOG_LEVEL: INFO
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "basic"
      - "mongodb-persistence"
      - "complete"

  persister:
    image: dojot/persister:${DOJOT_BACKEND_VERSION}
    restart: always
    depends_on:
      - mongodb
      - auth
      - kafka
      - data-broker
    environment:
      FALCON_SETTINGS_MODULE: 'history.settings.docker'
      DOJOT_MANAGEMENT_USER: 'persister'
      KAFKA_GROUP_ID: 'persister-group'
      LOG_LEVEL: INFO
      HISTORY_DB_DATA_EXPIRATION: 604800 #Time in seconds - Set to collection when device is created.
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "basic"
      - "mongodb-persistence"
      - "complete"

  mongodb:
    image: dojot/mongo:3.2
    restart: always
    user: "mongodb"
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongo mongodb:27017/test --quiet
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 40s
    volumes:
      - mongodb-volume:/data/db
      - mongodb-cfg-volume:/data/configdb
    command: '--wiredTigerCacheSizeGB 1'
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "basic"
      - "mongodb-persistence"
      - "data-processing"
      - "cron-job"
      - "x509-certificates"
      - "iot-agent-mqtt"
      - "iot-agent-http"
      - "import-export-configuration"
      - "complete"

  gui:
    image: dojot/gui:${DOJOT_FRONTEND_VERSION}
    depends_on:
      - backstage
    restart: always
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "basic"
      - "front-end"
      - "complete"

  gui-v2:
    image: dojot/gui-v2:${DOJOT_FRONTEND_VERSION}
    depends_on:
      - backstage
    restart: always
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "front-end"
      - "complete"

  data-broker:
    image: dojot/data-broker:${DOJOT_BACKEND_VERSION}
    restart: always
    depends_on:
      - kafka
      - data-broker-redis
      - auth
    environment:
      DOJOT_MANAGEMENT_USER: 'data-broker'
      KAFKA_GROUP_ID: 'data-broker-group'
      SERVICE_PORT: ${DATA_BROKER_SERVICE_PORT}
      DATA_BROKER_URL: 'http://data-broker:${DATA_BROKER_SERVICE_PORT}'
      LOG_LEVEL: 'info'
      KAFKA_NUM_PARTITIONS: 1
      KAFKA_REPLICATION_FACTOR: 1
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "basic"
      - "mongodb-persistence"
      - "data-processing"
      - "cron-job"
      - "lwm2m-iot-agent"
      - "iot-agent-mqtt"
      - "iot-agent-http"
      - "import-export-configuration"
      - "complete"

  data-broker-redis:
    image: dojot/redis:5.0.5-alpine3.10
    restart: always
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 1s
      timeout: 3s
      retries: 30
    volumes:
      - data-broker-redis-volume:/data
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "basic"
      - "mongodb-persistence"
      - "data-processing"
      - "cron-job"
      - "lwm2m-iot-agent"
      - "iot-agent-mqtt"
      - "iot-agent-http"
      - "import-export-configuration"
      - "complete"

################
# iot-agent lwm2m
################
  iotagent-lwm2m:
    image: dojot/iotagent-leshan:${DOJOT_BACKEND_VERSION}
    depends_on:
      - kafka
      - data-broker
      - auth
      - image-manager
    environment:
      DOJOT_MANAGEMENT_USER: 'iotagent-lwm2m'
      KAFKA_GROUP_ID: "iotagent-lwm2m-group"
      # The FILE_SERVER_ADDRESS should be filled with an address accesible to the devices that want to update the firmware
      FILE_SERVER_ADDRESS: ${DOJOT_DOMAIN_NAME:-localhost}
    ports:
      - 5896:5896 # file server http port
      - 5683:5683/udp # configuration coap port
      - 5684:5684/udp # configuration dtls port
      - 5693:5693/udp # file server coap port
      - 5694:5694/udp # file server dtls port
    restart: always
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "lwm2m-iot-agent"
      - "complete"

  image-manager:
    image: dojot/image-manager:${DOJOT_BACKEND_VERSION}
    restart: always
    depends_on:
      - postgres
      - minio
    environment:
      # TODO: The following should be unique for each environment
      S3ACCESSKEY: 9HEODSF6WQN5EZ39DM7Z
      S3SECRETKEY: fT5nAgHR9pkj0yYsBdc4p+PPq6ArjshcPdz0HA6W
      DBHOST: postgres
      DBUSER: imgm
      DBPASS: imgm
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "lwm2m-iot-agent"
      - "complete"

  minio:
    image: dojot/minio:2019.09.20
    restart: always
    depends_on:
      create_secrets:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    environment:
      MINIO_ACCESS_KEY_FILE: MINIO_ACCESS_KEY
      MINIO_SECRET_KEY_FILE: MINIO_SECRET_KEY
    secrets:
      - MINIO_SECRET_KEY
      - MINIO_ACCESS_KEY
    command: server /data
    volumes:
      - minio-volume:/data
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "lwm2m-iot-agent"
      - "complete"

  minio-files:
    image: minio/minio:RELEASE.2021-11-09T03-21-45Z
    restart: always
    depends_on:
      create_secrets:
        condition: service_completed_successfully
    hostname: minio-files
    command: server /data --console-address ":9001"
    volumes:
      - minio-image-volume:/data
      - ./secrets:/secrets
    ports:
      - "9010:9000"
      - "9011:9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9001/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    environment:
      MINIO_ACCESS_KEY_FILE: MINIO_ACCESS_KEY
      MINIO_SECRET_KEY_FILE: MINIO_SECRET_KEY
      MINIO_ROOT_USER_FILE: MINIO_ACCESS_KEY
      MINIO_ROOT_PASSWORD_FILE: MINIO_SECRET_KEY
    secrets:
      - MINIO_SECRET_KEY
      - MINIO_ACCESS_KEY
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "file-management"
      - "complete"

  createbuckets:
    image: minio/mc
    depends_on:
      create_secrets:
        condition: service_completed_successfully
      minio-files:
        condition: service_healthy
    volumes:
      - ./secrets:/secrets
    entrypoint: >
      /bin/sh -c "
      ACCESS_KEY=$$(cat /secrets/MINIO_ACCESS_KEY);
      SECRET_KEY=$$(cat /secrets/MINIO_SECRET_KEY);
      /usr/bin/mc config host add myminio http://minio-files:9000 $$ACCESS_KEY $$SECRET_KEY;
      /usr/bin/mc mb myminio/${MINIO_BUCKET_SUFFIX}admin
      "
    profiles:
      - "file-management"
      - "complete"

  file-mgmt:
    image: dojot/file-mgmt:${DOJOT_BACKEND_VERSION}
    restart: always
    depends_on:
      - minio-files
      - kafka
    volumes:
      - ./secrets:/secrets
    environment:
      FILEMGMT_SERVER_HOST: file-mgmt
      FILEMGMT_MINIO_ACCESS_KEY_FILE: MINIO_ACCESS_KEY
      FILEMGMT_MINIO_SECRET_KEY_FILE: MINIO_SECRET_KEY
      FILEMGMT_CONSUMER_METADATA_BROKER_LIST: kafka:9092
      FILEMGMT_MINIO_BUCKET_SUFFIX: ${MINIO_BUCKET_SUFFIX}
    secrets:
      - MINIO_SECRET_KEY
      - MINIO_ACCESS_KEY
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/health"]
      interval: 30s
      timeout: 20s
      retries: 3
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "file-management"
      - "complete"

  device-manager:
    image: dojot/device-manager:${DOJOT_BACKEND_VERSION}
    restart: always
    environment:
      # TODO: Fill these env variables with suitable values
      DEV_MNGR_CRYPTO_PASS: kamehameHA
      DEV_MNGR_CRYPTO_IV: 1234567890123456
      DEV_MNGR_CRYPTO_SALT: shuriken
      DBHOST: postgres
      DBUSER: devm
      DBPASS: devm
      LOG_LEVEL: INFO
    depends_on:
      - postgres
      - kafka
      - data-broker
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "basic"
      - "device-management"
      - "iot-agent-http"
      - "import-export-configuration"
      - "complete"

  postgres:
    image: dojot/postgres:9.5.21-alpine
    environment:
      POSTGRES_DB: postgres
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD_FILE: /secrets/.POSTGRES_PASSWORD
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: always
    volumes:
      - ./postgres/init-db.sh:/docker-entrypoint-initdb.d/init-db.sh:Z
      - postgres-volume:/var/lib/postgresql/data
      - ./secrets:/secrets
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "basic"
      - "device-management"
      - "x509-certificates"
      - "mongodb-persistence"
      - "front-end"
      - "data-processing"
      - "cron-job"
      - "lwm2m-iot-agent"
      - "api-gateway"
      - "user-management"
      - "iot-agent-mqtt"
      - "iot-agent-http"
      - "import-export-configuration"
      - "complete"

  # Prepare database, Bootstrap the database
  kong-migrations:
    image: dojot/kong:${DOJOT_BACKEND_VERSION}
    command: kong migrations bootstrap
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      KONG_DATABASE: postgres
      KONG_PG_HOST: postgres
      KONG_PG_USER: kong
      KONG_PG_DATABASE: kong
      KONG_LOG_LEVEL: info
      KONG_PG_PASSWORD_FILE: /secrets/.KONG_PASSWORD
    restart: on-failure
    volumes:
      - ./secrets:/secrets
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "basic"
      - "api-gateway"
      - "front-end"
      - "mongodb-persistence"
      - "data-processing"
      - "cron-job"
      - "lwm2m-iot-agent"
      - "user-management"
      - "iot-agent-mqtt"
      - "iot-agent-http"
      - "import-export-configuration"
      - "complete"

  # Run any new migrations and Finish running any pending migrations after 'up'.
  kong-migrations-up:
    image:  dojot/kong:${DOJOT_BACKEND_VERSION}
    command: kong migrations up && kong migrations finish
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      KONG_DATABASE: postgres
      KONG_PG_HOST: postgres
      KONG_PG_USER: kong
      KONG_PG_DATABASE: kong
      KONG_PG_PASSWORD_FILE: /secrets/.KONG_PASSWORD
      KONG_LOG_LEVEL: info
    restart: on-failure
    volumes:
      - ./secrets:/secrets
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "basic"
      - "api-gateway"
      - "front-end"
      - "mongodb-persistence"
      - "data-processing"
      - "cron-job"
      - "lwm2m-iot-agent"
      - "user-management"
      - "iot-agent-mqtt"
      - "iot-agent-http"
      - "import-export-configuration"
      - "complete"

  apigw:
    image: dojot/kong:${DOJOT_BACKEND_VERSION}
    depends_on:
      postgres:
        condition: service_healthy
      kong-migrations:
        condition: service_started
      kong-migrations-up:
        condition: service_started
    environment:
      KONG_DATABASE: postgres
      KONG_PG_HOST: postgres
      KONG_PG_USER: kong
      KONG_PG_DATABASE: kong
      KONG_PG_PASSWORD_FILE: /secrets/.KONG_PASSWORD
      KONG_LOG_LEVEL: info
      # To enable HTTPs external, it is necessary to configure public certificates
      # issued by a public CA, such as lets encrypt in KONG_SSL_CERT.
      # KONG_SSL_CERT_KEY: /certs/example-external.key
      # KONG_SSL_CERT: /certs/example-external.crt
      # To enable HTTPs internal with mutual authentication, it is necessary to configure public certificates
      # issued by a EJBCA internal from dojot in KONG_NGINX_PROXY_PROXY_SSL_CERTIFICATE.
      # KONG_NGINX_PROXY_PROXY_SSL_CERTIFICATE_KEY: /certs/example-internal.key
      # KONG_NGINX_PROXY_PROXY_SSL_CERTIFICATE: /certs/example-internal.crt
      # Root cerficate from internal CA
      # KONG_NGINX_PROXY_PROXY_SSL_TRUSTED_CERTIFICATE: /certs/root-ca-internal.crt
      # KONG_NGINX_PROXY_PROXY_SSL_VERIFY: "on"
      # KONG_NGINX_PROXY_PROXY_SSL_VERIFY_DEPTH: "2"
    ports:
      - "8000:8000/tcp"
      # Proxy listen to HTTPS traffic (8443). services and routes must be configured to use the https protocol
      # Each service must have its certificate with Subject Alternative Name generated by dojot's EJBCA.
      #- "8443:8443/tcp"
    healthcheck:
      test: ["CMD", "kong", "health"]
      interval: 10s
      timeout: 10s
      retries: 10
    # Exposes certificates
    #volumes:
    #  - ./kong/certificates/:/certs/:Z
    restart: always
    volumes:
      - ./secrets:/secrets
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "basic"
      - "front-end"
      - "api-gateway"
      - "mongodb-persistence"
      - "data-processing"
      - "cron-job"
      - "lwm2m-iot-agent"
      - "user-management"
      - "iot-agent-mqtt"
      - "iot-agent-http"
      - "import-export-configuration"
      - "complete"

  kong-config:
    image: dojot/appropriate-curl
    entrypoint: /opt/kong.config.sh
    restart: on-failure
    depends_on:
      - apigw
    volumes:
      - ./kong/kong.config.sh:/opt/kong.config.sh:Z
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "basic"
      - "api-gateway"
      - "complete"

  auth:
    image: dojot/auth:${DOJOT_BACKEND_VERSION}
    restart: always
    depends_on:
      - apigw
      - postgres
      - auth-redis
    environment:
      AUTH_DB_HOST: "postgres"
      AUTH_DB_USER: "auth"
      AUTH_DB_PWD:  "auth"
      AUTH_KONG_URL: "http://apigw:8001"
      AUTH_CACHE_HOST: "auth-redis"
      AUTH_RESET_PWD_VIEW: "http://${DOJOT_DOMAIN_NAME}:8000/#/setPassword/" #When using a front end with Auth, define this link to point to the password reset view.
      AUTH_EMAIL_HOST: NOEMAIL # SMTP server to be used. If set to NOEMAIL, this functionality is disabled.
      AUTH_EMAIL_PORT: 587 # SMTP server port.
      AUTH_EMAIL_TLS: "true" # Whether to enable TLS or not for SMTP server.
      AUTH_EMAIL_USER: "" # SMTP user.
      AUTH_EMAIL_PASSWD: "" # SMTP password.
      AUTH_USER_TMP_PWD: "temppwd" # The default temporary password that is given to new users if AUTH_EMAIL_HOST is set to NOEMAIL.
      # This is used to select the type of cache to be used.
      # Allowed values are "redis" or "nocache"
      AUTH_CACHE_NAME: "redis"
      DOJOT_MANAGEMENT_USER: 'auth'
      KAFKA_GROUP_ID: 'auth-group'
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "basic"
      - "user-management"
      - "mongodb-persistence"
      - "data-processing"
      - "cron-job"
      - "front-end"
      - "lwm2m-iot-agent"
      - "iot-agent-mqtt"
      - "iot-agent-http"
      - "import-export-configuration"
      - "complete"

  auth-redis:
    image: dojot/redis:5.0.5-alpine3.10
    restart: always
    volumes:
      - auth-redis-volume:/data
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "basic"
      - "user-management"
      - "mongodb-persistence"
      - "data-processing"
      - "cron-job"
      - "front-end"
      - "lwm2m-iot-agent"
      - "iot-agent-mqtt"
      - "iot-agent-http"
      - "import-export-configuration"
      - "complete"

  flowbroker:
    image: dojot/flowbroker:${DOJOT_BACKEND_VERSION}
    restart: always
    environment:
      DEPLOY_ENGINE: "docker"
      FLOWBROKER_NETWORK: ${FLOWBROKER_NETWORK}
      DOJOT_MANAGEMENT_USER: 'flowbroker'
      KAFKA_GROUP_ID: 'flowbroker-group'
      LOG_LEVEL: 'info'
    depends_on:
      - rabbitmq
      - kafka
      - mongodb
      - auth
      - flowbroker-context-manager
      - flowbroker-redis
      - data-broker
    networks:
      - default
      - ${FLOWBROKER_NETWORK}
    volumes:
      - flowbroker-volume:/data
      - /var/run/docker.sock:/var/run/docker.sock:Z
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "data-processing"
      - "import-export-configuration"
      - "complete"

  flowbroker-redis:
    image: dojot/redis:5.0.5-alpine3.10
    restart: always
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 1s
      timeout: 3s
      retries: 30
    volumes:
      - flowbroker-redis-volume:/data
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "data-processing"
      - "import-export-configuration"
      - "complete"

  flowbroker-context-manager:
    image: dojot/flowbroker-context-manager:${DOJOT_BACKEND_VERSION}
    restart: always
    environment:
      ZOOKEEPER_HOST: zookeeper
      ZOOKEEPER_PORT: 2181
      ZEROMQ_PORT: 5556
      HOLD_LOCK_TIMEOUT: 10000
      WAIT_LOCK_TIMEOUT: 30000
    depends_on:
      - zookeeper
    networks:
      - default
      - flowbroker
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "data-processing"
      - "data-processing-context"
      - "import-export-configuration"
      - "complete"

  rabbitmq:
    image: rabbitmq:3.9.10-management-alpine
    restart: unless-stopped
    hostname: rabbitmq
    cap_add:
      - ALL
    ulimits:
      nofile:
        soft: 2000
        hard: 2000
    healthcheck:
      test: rabbitmq-diagnostics -q ping
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 10s
    volumes:
      - type: volume
        source: rabbitmq-volume
        target: /var/lib/rabbitmq
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "data-processing"
      - "import-export-configuration"
      - "complete"

  zookeeper:
    image: "confluentinc/cp-zookeeper:5.5.0"
    restart: always
    healthcheck:
      test: echo stat | nc localhost 2181
      interval: 10s
      timeout: 10s
      retries: 3
    environment:
      ZOOKEEPER_REPLICAS: "1"
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_ELECTION_PORT: 3888
      ZOOKEEPER_SERVER_PORT: 2888
      ZOOKEEPER_HEAP_SIZE: "2G"
      ZOOKEEPER_INIT_LIMIT: "5"
      ZOOKEEPER_LOG_LEVEL: "INFO"
      ZOOKEEPER_MAX_CLIENT_CNXNS: "100"
      ZOOKEEPER_MAX_SESSION_TIMEOUT: "40000"
      ZOOKEEPER_MIN_SESSION_TIMEOUT: "4000"
      ZOOKEEPER_PURGE_INTERVAL: "0"
      ZOOKEEPER_SNAP_RETAIN_COUNT: "3"
      ZOOKEEPER_SYNC_LIMIT: "10"
      ZOOKEEPER_TICK_TIME: "2000"
    volumes:
      - zookeeper-volume:/var/lib/zookeeper/data
      - zookeeper-log-volume:/var/lib/zookeeper/log
      - zookeeper-secrets-volume:/etc/zookeeper/secrets
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "basic"
      - "data-processing-context"
      - "data-processing"
      - "mongodb-persistence"
      - "cron-job"
      - "x509-certificates"
      - "lwm2m-iot-agent"
      - "websocket-real-time"
      - "iot-agent-mqtt"
      - "iot-agent-http"
      - "import-export-configuration"
      - "file-management"
      - "influxdb-persistence"
      - "complete"

  kafka:
    image: confluentinc/cp-kafka:5.5.0
    depends_on:
      - zookeeper
    restart: always
    hostname: "kafka"
    environment:
      KAFKA_BROKER_ID: "1"
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://:9092"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: "1"
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: "1"
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: "0"
      KAFKA_LOG_RETENTION_MINUTES: "30" # is the max time an individual message should remain
      KAFKA_LOG_SEGMENT_BYTES: "262144000"
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: "30000"
    healthcheck:
      test: ps augwwx | egrep [S]upportedKafka
    volumes:
      - kafka-volume:/var/lib/kafka/data
      - kafka-secrets-volume:/etc/kafka/secrets
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "basic"
      - "mongodb-persistence"
      - "data-processing"
      - "cron-job"
      - "x509-certificates"
      - "lwm2m-iot-agent"
      - "websocket-real-time"
      - "iot-agent-mqtt"
      - "iot-agent-http"
      - "import-export-configuration"
      - "file-management"
      - "influxdb-persistence"
      - "complete"

  x509-identity-mgmt:
    image: dojot/x509-identity-mgmt:${DOJOT_BACKEND_VERSION}
    depends_on:
      - x509-ejbca
      - postgres
      - mongodb
      - kafka
    restart: always
    environment:
      NODE_ENV: production
      X509IDMGMT_LOGGER_CONSOLE_LEVEL: info
      X509IDMGMT_CERTIFICATE_BELONGSTO_APPLICATION: '["iotagent-mqtt", "v2k-bridge", "k2v-bridge", "http-agent"]'
      X509IDMGMT_MONGO_CONN_URI: "mongodb://mongodb:27017/x509-identity-mgmt"
      X509IDMGMT_EJBCA_HEALTHCHECK_URL: "http://x509-ejbca:8080/ejbca/publicweb/healthcheck/ejbcahealth"
      X509IDMGMT_EJBCA_WSDL: "https://x509-ejbca:8443/ejbca/ejbcaws/ejbcaws?wsdl"
      # X509IDMGMT_CERTIFICATE_CHECK_SUBJECTDN: "true" # add to CN `tenant:deviceid`
      # ROARR_LOG: "true" # healthcheck is using 'Roarr' to implement logging.
    healthcheck:
      test: ["CMD", "wget", "-q", "-O", "-", "http://localhost:9000/health"]
      interval: 10s
      timeout: 10s
      retries: 6
      start_period: 2m
    volumes:
      - "ejbca-client-tls-volume:/opt/tls"
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "basic"
      - "x509-certificates"
      - "iot-agent-mqtt"
      - "iot-agent-http"
      - "complete"

  x509-ejbca: # this service cannot be called 'ejbca'
    image: dojot/ejbca:${DOJOT_BACKEND_VERSION}
    depends_on:
      - postgres
    restart: always
    hostname: "x509-ejbca" # The 'hostname' must have the same name as the 'service'
                           # and cannot be called 'ejbca' so as not to conflict with
                           # the ejbca's internal End-Entity (hidden)
    domainname: "" # the 'domainname' must remain empty unless the
                   # service name contains periods (such as an FQDN)
    environment:
      DATABASE_JDBC_URL: jdbc:postgresql://postgres:5432/ejbca?characterEncoding=UTF-8
      DATABASE_USER: ejbca
      DATABASE_PASSWORD: ejbca
      EJBCA_EXTERNAL_ACCESS: "true" # to make the Wildfly server visible on the x509-identity-mgmt
      EJBCA_SERVER_CERT_REGEN: "true" # Used to force the generation of a new certificate for the server
      # EJBCA_LOCK_FILE_TIMEOUT: "0" # Used to break the '.lock' file
      # EJBCA_ADMIN_USER: "true" # Access to the EJBCA web interface is useful for debugging purposes
    healthcheck:
      test: ["CMD", "curl", "http://localhost:8080/ejbca/publicweb/healthcheck/ejbcahealth"]
      interval: 30s
      timeout: 10s
      retries: 2
      start_period: 2m
    volumes:
      - "ejbca-volume:/mnt/persistent"
      - "ejbca-client-tls-volume:/opt/tls"
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "basic"
      - "x509-certificates"
      - "iot-agent-mqtt"
      - "iot-agent-http"
      - "complete"

  kafka-ws:
    image: dojot/kafka-ws:${DOJOT_BACKEND_VERSION}
    depends_on:
      - kafka
      - kafka-ws-redis
    environment:
      KAFKA_WS_SERVER_JWT_EXP_TIME: "true"
      KAFKA_WS_REDIS_HOST: kafka-ws-redis
      KAFKA_WS_LOG_CONSOLE_LEVEL: "info"
      # The KAFKA_WS_TICKET_SECRET should be unique for each environment
      KAFKA_WS_TICKET_SECRET: fT5nAgHR9pkj0yYsBdc4p+PPq6ArjshcPdz0HA6W
    restart: always
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "websocket-real-time"
      - "complete"

  kafka-ws-redis:
    image: dojot/redis:6.0.4-alpine3.11
    restart: always
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 1s
      timeout: 3s
      retries: 30
    volumes:
      - kafka-ws-redis-volume:/data
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "websocket-real-time"
      - "complete"

  acl-redis:
    image: dojot/redis:6.0.4-alpine3.11
    restart: always
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 1s
      timeout: 3s
      retries: 30
    volumes:
      - acl-redis-volume:/data
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "basic"
      - "x509-certificates"
      - "iot-agent-mqtt"
      - "complete"
      - "iot-agent-http"

  certificate-acl:
    image: dojot/certificate-acl:${DOJOT_BACKEND_VERSION}
    environment:
      CERTIFICATE_ACL_LOGGER_CONSOLE_LEVEL: "info"
    depends_on:
      - acl-redis
      - kafka
      - x509-identity-mgmt
    restart: always
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "basic"
      - "x509-certificates"
      - "iot-agent-mqtt"
      - "complete"
      - "iot-agent-http"

  iotagent-mqtt:
    image: dojot/vernemq-dojot:${DOJOT_BACKEND_VERSION}
    command: ["/bin/bash", "-c", "echo $$VERNEMQ_CONF | base64 -d > /etc/vernemq/vernemq.conf; echo $$VM_ARGS | base64 -d > /etc/vernemq/vm.args; start_vernemq"]
    depends_on:
      - iotagent-mqtt-cert-sidecar
      - certificate-acl
    ports:
      - 1883:1883 # You can comment this line (- 1883:1883) to disable insecure mode without TLS. (this is recommended)
      - 8883:8883
    environment:
      VERNEMQ_CONF: bWV0YWRhdGFfcGx1Z2luID0gdm1xX3N3YwpwbHVnaW5zLnZtcV9wYXNzd2QgPSBvZmYKcGx1Z2lucy52bXFfYWNsID0gb2ZmCnBsdWdpbnMuZG9qb3RfZGlzY29ubmVjdF9wbHVnaW4ucGF0aCA9IC92ZXJuZW1xL2Rvam90X2Rpc2Nvbm5lY3RfcGx1Z2luL2RlZmF1bHQKcGx1Z2lucy5kb2pvdF9kaXNjb25uZWN0X3BsdWdpbiA9IG9uCnBsdWdpbnMuZG9qb3RfZGlzY29ubmVjdF9wbHVnaW4ucHJpb3JpdHkgPSAyCnBsdWdpbnMuZG9qb3RfYWNsX3BsdWdpbi5wYXRoID0gL3Zlcm5lbXEvZG9qb3RfYWNsX3BsdWdpbi9kZWZhdWx0CnBsdWdpbnMuZG9qb3RfYWNsX3BsdWdpbiA9IG9uCnBsdWdpbnMuZG9qb3RfYWNsX3BsdWdpbi5wcmlvcml0eSA9IDIKbGV2ZWxkYi5tYXhpbXVtX21lbW9yeS5wZXJjZW50ID0gMjAKbG9nLmNvbnNvbGUgPSBjb25zb2xlCmxpc3RlbmVyLm1heF9jb25uZWN0aW9ucyA9IDIwMDAwMApsaXN0ZW5lci5ucl9vZl9hY2NlcHRvcnMgPSAxMDAKbWF4X2luZmxpZ2h0X21lc3NhZ2VzID0gMjAKbWF4X29ubGluZV9tZXNzYWdlcyA9IDEwMDAwCmxpc3RlbmVyLmh0dHAuZGVmYXVsdCA9IDAuMC4wLjA6ODg4OApsaXN0ZW5lci5zc2wuZGVmYXVsdCA9IDAuMC4wLjA6ODg4MwpsaXN0ZW5lci5zc2wuZGVmYXVsdC5jYWZpbGUgPSAgL3Zlcm5lbXEvY2VydC9jYWJ1bmRsZS5jcnQKbGlzdGVuZXIuc3NsLmRlZmF1bHQuY2VydGZpbGUgPSAvdmVybmVtcS9jZXJ0L2lvdGFnZW50LW1xdHQuY3J0Cmxpc3RlbmVyLnNzbC5kZWZhdWx0LmtleWZpbGUgPSAvdmVybmVtcS9jZXJ0L2lvdGFnZW50LW1xdHQua2V5Cmxpc3RlbmVyLnNzbC5kZWZhdWx0LmNybGZpbGUgPSAgL3Zlcm5lbXEvY2VydC9jYS5jcmwKbGlzdGVuZXIuc3NsLmRlZmF1bHQudXNlX2lkZW50aXR5X2FzX3VzZXJuYW1lID0gb24KbGlzdGVuZXIuc3NsLmRlZmF1bHQucmVxdWlyZV9jZXJ0aWZpY2F0ZSA9IG9uCmxpc3RlbmVyLnNzbC5pbnRlcm5hbCA9IDAuMC4wLjA6OTg4MwpsaXN0ZW5lci5zc2wuaW50ZXJuYWwuY2FmaWxlID0gIC92ZXJuZW1xL2NlcnQvY2FidW5kbGUuY3J0Cmxpc3RlbmVyLnNzbC5pbnRlcm5hbC5jZXJ0ZmlsZSA9IC92ZXJuZW1xL2NlcnQvaW90YWdlbnQtbXF0dC5jcnQKbGlzdGVuZXIuc3NsLmludGVybmFsLmtleWZpbGUgPSAvdmVybmVtcS9jZXJ0L2lvdGFnZW50LW1xdHQua2V5Cmxpc3RlbmVyLnNzbC5pbnRlcm5hbC5jcmxmaWxlID0gIC92ZXJuZW1xL2NlcnQvY2EuY3JsCmxpc3RlbmVyLnNzbC5pbnRlcm5hbC5yZXF1aXJlX2NlcnRpZmljYXRlID0gb24=
      VM_ARGS: K1AgMjU2MDAwCi1lbnYgRVJMX01BWF9FVFNfVEFCTEVTIDI1NjAwMAotZW52IEVSTF9DUkFTSF9EVU1QIC92ZXJuZW1xL2xvZy9lcmxfY3Jhc2guZHVtcAotZW52IEVSTF9GVUxMU1dFRVBfQUZURVIgMAotZW52IEVSTF9NQVhfUE9SVFMgMjYyMTQ0CitBIDY0Ci1zZXRjb29raWUgdm1xCi1uYW1lIHZtcUBpb3RhZ2VudC1tcXR0LmRvam90LmlvdAorSyB0cnVlCitXIHcKLXNtcCBlbmFibGU=
    restart: always
    hostname: iotagent-mqtt
    domainname: dojot.iot
    volumes:
      - iotagent-mqtt-volume:/vernemq/data
      - iotagent-mqtt-log-volume:/vernemq/log
      - iotagent-mqtt-etc-volume:/vernemq/etc
      - iotagent-mqtt-cert-side-volume:/vernemq/cert
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "iot-agent-mqtt"
      - "complete"

  iotagent-mqtt-cert-sidecar:
    image: dojot/cert-sidecar:${DOJOT_BACKEND_VERSION}
    depends_on:
      - x509-identity-mgmt
    environment:
      CERT_SC_APP_SIDECAR_TO: 'iotagent-mqtt'
      CERT_SC_LOG_CONSOLE_LEVEL: 'info'
      # About CERT_SC_CERTS_HOSTNAMES
      #     Servers hostname/ip (the list of host to which the device connects); The value "iotagent-mqtt" is mandatory, it is used by v2k and k2v.
      #     It's the old EXTERNAL_SERVER_HOSTNAME and equivalent to MOSCA_TLS_DNS_LIST.
      CERT_SC_CERTS_HOSTNAMES: '["iotagent-mqtt", "${DOJOT_DOMAIN_NAME:-localhost}"]'
      HOSTNAME: iotagent-mqtt
      CERT_SC_CERTS_FILES_BASEPATH: /vernemq/cert
      CERT_SC_CERTS_FILES_CA: ca.crt
      CERT_SC_CERTS_FILES_CERT: iotagent-mqtt.crt
      CERT_SC_CERTS_FILES_KEY: iotagent-mqtt.key
      CERT_SC_CERTS_FILES_CRL: ca.crl
      CERT_SC_CERTS_FILES_CABUNDLE: cabundle.crt
      CERT_SC_CRON_CABUNDLE: "true"
    volumes:
      - iotagent-mqtt-cert-side-volume:/vernemq/cert
    restart: always
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "iot-agent-mqtt"
      - "x509-certificates"
      - "complete"

  v2k-bridge:
    image: dojot/v2k-bridge:${DOJOT_BACKEND_VERSION}
    depends_on:
      - iotagent-mqtt
      - kafka
      - v2k-bridge-cert-sidecar
      - data-broker
    environment:
      V2K_APP_HOSTNAME: "v2k-bridge"
      V2K_APP_USER_CONFIG_FILE: "docker.conf"
      V2K_PRODUCER_METADATA_BROKER_LIST: "kafka:9092"
      V2K_MQTT_PORT: 9883
      V2K_MQTT_CA: "/certs/ca.crt"
      V2K_MQTT_CERT: "/certs/v2k-bridge.crt"
      V2K_MQTT_KEY:  "/certs/v2k-bridge.key"
      V2K_LOG_CONSOLE_LEVEL: "info"
    restart: always
    volumes:
      - v2k-bridge-cert-side-volume:/certs
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "iot-agent-mqtt"
      - "complete"

  v2k-bridge-cert-sidecar:
    image: dojot/cert-sidecar:${DOJOT_BACKEND_VERSION}
    depends_on:
      - x509-identity-mgmt
    environment:
      CERT_SC_APP_SIDECAR_TO: 'v2k-bridge'
      CERT_SC_LOG_CONSOLE_LEVEL: 'info'
      CERT_SC_CERTS_CRL: 'false'
      CERT_SC_CERTS_HOSTNAMES: '["v2k-bridge"]'
      HOSTNAME: v2k-bridge
      CERT_SC_CERTS_FILES_BASEPATH: /certs
      CERT_SC_CERTS_FILES_CA: ca.crt
      CERT_SC_CERTS_FILES_CERT: v2k-bridge.crt
      CERT_SC_CERTS_FILES_KEY: v2k-bridge.key
    volumes:
      - v2k-bridge-cert-side-volume:/certs
    restart: always
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "iot-agent-mqtt"
      - "x509-certificates"
      - "complete"

  k2v-bridge:
    image: dojot/k2v-bridge:${DOJOT_BACKEND_VERSION}
    depends_on:
      - iotagent-mqtt
      - kafka
      - k2v-bridge-cert-sidecar
      - data-broker
    environment:
      K2V_APP_HOSTNAME: "k2v-bridge"
      K2V_APP_USER_CONFIG_FILE: "docker.conf"
      K2V_CONSUMER_METADATA_BROKER_LIST: "kafka:9092"
      K2V_MQTT_PORT: 9883
      K2V_MQTT_CA: "/certs/ca.crt"
      K2V_MQTT_CERT: "/certs/k2v-bridge.crt"
      K2V_MQTT_KEY: "/certs/k2v-bridge.key"
      K2V_LOG_CONSOLE_LEVEL: "info"
    restart: always
    volumes:
      - k2v-bridge-cert-side-volume:/certs
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "iot-agent-mqtt"
      - "complete"

  k2v-bridge-cert-sidecar:
    image: dojot/cert-sidecar:${DOJOT_BACKEND_VERSION}
    depends_on:
      - x509-identity-mgmt
    environment:
      CERT_SC_APP_SIDECAR_TO: 'k2v-bridge'
      CERT_SC_LOG_CONSOLE_LEVEL: 'info'
      CERT_SC_CERTS_CRL: 'false'
      CERT_SC_CERTS_HOSTNAMES: '["k2v-bridge"]'
      HOSTNAME: k2v-bridge
      CERT_SC_CERTS_FILES_BASEPATH: /certs
      CERT_SC_CERTS_FILES_CA: ca.crt
      CERT_SC_CERTS_FILES_CERT: k2v-bridge.crt
      CERT_SC_CERTS_FILES_KEY: k2v-bridge.key
    volumes:
      - k2v-bridge-cert-side-volume:/certs
    restart: always
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "iot-agent-mqtt"
      - "x509-certificates"
      - "complete"

  http-agent-cert-sidecar:
    image: dojot/cert-sidecar:${DOJOT_BACKEND_VERSION}
    depends_on:
      - x509-identity-mgmt
    environment:
      CERT_SC_APP_SIDECAR_TO: 'http-agent'
      CERT_SC_LOG_CONSOLE_LEVEL: 'info'
      CERT_SC_CERTS_HOSTNAMES: '["http-agent", "${DOJOT_DOMAIN_NAME:-localhost}"]'
      HOSTNAME: http-agent
      CERT_SC_CERTS_FILES_BASEPATH: /certs
      CERT_SC_CERTS_FILES_CA: ca.crt
      CERT_SC_CERTS_FILES_CERT: http-agent.crt
      CERT_SC_CERTS_FILES_KEY: http-agent.key
      CERT_SC_CERTS_FILES_CRL: ca.crl
      CERT_SC_CERTS_FILES_CABUNDLE: cabundle.crt
      CERT_SC_CRON_CABUNDLE: "true"
    volumes:
      - http-agent-cert-sidecar-volume:/certs
    restart: always
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "basic"
      - "iot-agent-http"
      - "x509-certificates"
      - "complete"

  http-agent:
    image: dojot/http-agent:${DOJOT_BACKEND_VERSION}
    restart: always
    depends_on:
      - kafka
      - data-broker
      - auth
      - http-agent-cert-sidecar
      - device-manager
      - certificate-acl
      - basic-auth
    ports:
      - 8080:3000
    environment:
      HTTP_AGENT_HTTPS_CERT: '/certs/http-agent.crt'
      HTTP_AGENT_HTTPS_KEY: '/certs/http-agent.key'
      HTTP_AGENT_HTTPS_CA: '/certs/cabundle.crt'
      HTTP_AGENT_SECURITY_CRL: '/certs/ca.crl'
      HTTP_AGENT_SECURITY_CERT_DIRECTORY: '/certs'
      HTTP_AGENT_LOG_CONSOLE_LEVEL: 'info'
    volumes:
      - http-agent-cert-sidecar-volume:/certs
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "basic"
      - "iot-agent-http"
      - "complete"

  http-agent-redis:
    image: dojot/redis:6.0.4-alpine3.11
    restart: always
    volumes:
      - http-agent-redis-volume:/data
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "basic"
      - "iot-agent-http"
      - "complete"

  data-manager:
    image: dojot/data-manager:${DOJOT_BACKEND_VERSION}
    restart: always
    depends_on:
      - flowbroker
      - device-manager
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "import-export-configuration"
      - "complete"

  backstage:
    image: dojot/backstage:${DOJOT_FRONTEND_VERSION}
    restart: always
    depends_on:
      - postgres
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "basic"
      - "front-end"
      - "complete"

  cron:
    image: dojot/cron:${DOJOT_BACKEND_VERSION}
    restart: always
    depends_on:
      - kafka
      - data-broker
      - auth
      - mongodb
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "data-processing"
      - "cron-job"
      - "complete"

### influxdb begin

  influxdb-retriever:
    image: dojot/influxdb-retriever:${DOJOT_BACKEND_VERSION}
    depends_on:
      - influxdb
    environment:
      RETRIEVER_LOG_CONSOLE_LEVEL: "info"
    restart: always
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "influxdb-persistence"
      - "complete"

  influxdb-storer:
    image: dojot/influxdb-storer:${DOJOT_BACKEND_VERSION}
    depends_on:
      - kafka
      - influxdb
    environment:
      STORER_LOG_CONSOLE_LEVEL: "info"
      STORER_INFLUX_RETENTION_HRS: 168 # used only for new created tenant after default
    restart: always
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "influxdb-persistence"
      - "complete"

  influxdb-setup:
    image: quay.io/influxdb/influxdb:v2.0.2
    deploy:
      restart_policy:
        condition: on-failure
        max_attempts: 3
    environment:
      DEFAULT_RETENTION: "7d" # default (admin) organization expiry time
    volumes:
      - influxdb-volume:/root/.influxdbv2/
      - ./influxdb/init-influx.sh:/init-influx.sh:Z
    entrypoint:
      - /init-influx.sh
    depends_on:
      influxdb:
        condition: service_healthy
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "influxdb-persistence"
      - "complete"

  influxdb:
    image: quay.io/influxdb/influxdb:v2.0.2
    restart: always
    ports:
      - 8086:8086
    volumes:
      - influxdb-volume:/root/.influxdbv2
    healthcheck:
      test: "influx ping"
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "influxdb-persistence"
      - "complete"

# ### Interface WEB InfluxDB
# ### Created user dojot_admin to acess interface WEB InfluxDB
  influxdb-chronograf:
    image: chronograf:1.9.1
    depends_on:
      - influxdb
    ports:
      - '127.0.0.1:8888:8888'
    volumes:
      - influxdb-chronograf-volume:/var/lib/chronograf
    environment:
      - INFLUXDB_URL=http://influxdb:8086
      - INFLUXDB_USERNAME=admin
      - INFLUXDB_PASSWORD=admin
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "influxdb-persistence"
      - "complete"

### influxdb end

  # GUI to Kong Admin API - BEGIN
  # Konga GUI will be available at http://localhost:1337
  #
  konga:
    image: dojot/pantsel_konga:0.14.7
    ports:
      - 1337:1337
    environment:
      DB_ADAPTER: mongo
      DB_DATABASE: konga
      DB_HOST: mongodb
      KONGA_LOG_LEVEL: info
      NO_AUTH: "true"
      KONGA_SEED_KONG_NODE_DATA_SOURCE_FILE: /konga.js
      NODE_ENV: production
      BASE_URL: ${DOJOT_DOMAIN_NAME:-"localhost"}
    volumes:
      - ./kong/konga.config.js:/konga.js:ro
    restart: on-failure
    logging:
      driver: json-file
      options:
        max-size: 20m
        max-file: '5'
    profiles:
      - "tools"


  # GUI to Kafka - BEGIN
  kafdrop:
    image: obsidiandynamics/kafdrop:latest
    ports:
      - 9090:9000
    environment:
      KAFKA_BROKERCONNECT: "kafka:9092"
      JVM_OPTS: "-Xms32M -Xmx64M"
      SERVER_SERVLET_CONTEXTPATH: "/"
    restart: on-failure
    logging:
      driver: json-file
      options:
        max-size: 20m
        max-file: '5'
    profiles:
      - "tools"

# GUI to mongo - BEGIN
# GUI will be available at http://${DOJOT_DOMAIN_NAME}:8383
  mongo-express-gui:
    image: mongo-express
    restart: always
    environment:
      ME_CONFIG_MONGODB_SERVER: mongodb
    ports:
      - "8383:8081"
    profiles:
      - "tools"

# GUI to postgres - BEGIN
# GUI will be available at http://${DOJOT_DOMAIN_NAME}:5050
  pgadmin:
    image: dpage/pgadmin4
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@pgadmin.com
      PGADMIN_DEFAULT_PASSWORD: admin
    restart: always
    ports:
      - 5050:80
    profiles:
    - "tools"

  basic-auth:
    image: dojot/device-basic-authentication:${DOJOT_BACKEND_VERSION}
    restart: always
    depends_on:
      - kafka
      - data-broker
      - mongodb
      - auth
      - device-manager
    environment:
      BASIC_AUTH_LOG_CONSOLE_LEVEL: 'info'
      BASIC_AUTH_LOG_VERBOSE: "true"
      BASIC_AUTH_PRODUCER_METADATA_BROKER_LIST: kafka:9092
    <<: [*loki-logging, *dojot-networking]
    profiles:
      - "basic"
      - "iot-agent-http"
      - "complete"

volumes:
  ejbca-volume:
  ejbca-client-tls-volume:
  postgres-volume:
  mongodb-volume:
  mongodb-cfg-volume:
  minio-volume:
  minio-image-volume:
  rabbitmq-volume:
  zookeeper-volume:
  zookeeper-log-volume:
  zookeeper-secrets-volume:
  kafka-volume:
  kafka-secrets-volume:
  iotagent-mqtt-volume:
  iotagent-mqtt-log-volume:
  iotagent-mqtt-etc-volume:
  iotagent-mqtt-cert-side-volume:
  v2k-bridge-cert-side-volume:
  k2v-bridge-cert-side-volume:
  auth-redis-volume:
  flowbroker-volume:
  flowbroker-redis-volume:
  data-broker-redis-volume:
  kafka-ws-redis-volume:
  mosca-redis-volume:
  influxdb-volume:
  influxdb-chronograf-volume:
  acl-redis-volume:
  http-agent-cert-sidecar-volume:
  http-agent-redis-volume:

secrets:
  MINIO_SECRET_KEY:
    file: ./secrets/MINIO_SECRET_KEY
  MINIO_ACCESS_KEY:
    file: ./secrets/MINIO_ACCESS_KEY

networks:
  default:
    name: dojot
  flowbroker:
    name: ${FLOWBROKER_NETWORK}
